{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline                                           \n",
    "from sklearn.preprocessing import StandardScaler                                     \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.base import clone\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from skbio.stats.ordination import pcoa\n",
    "import umap\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta data\n",
    "df_meta = pd.read_csv('../../../../../../our_data/meta_data.csv', index_col=0)\n",
    "df_meta = df_meta[df_meta.Diet=='Inulin'] # only for inulin group\n",
    "df_meta = df_meta[df_meta.Day != 0] # remove day 0\n",
    "\n",
    "# read SCFA data\n",
    "df_scfa = pd.read_csv('../../../../../../our_data/SCFA.csv', index_col=0)\n",
    "\n",
    "# read bacterial abundance (asv level)\n",
    "df_bac = pd.read_csv('../../../../../../our_data/16S_absolute_abundance_asv.csv', index_col=0).T\n",
    "\n",
    "# find common samples\n",
    "common_samples = list(set(df_meta.index).intersection(df_scfa.index).intersection(df_bac.index))\n",
    "df_meta = df_meta.loc[common_samples]\n",
    "df_scfa = df_scfa.loc[common_samples]\n",
    "df_bac = df_bac.loc[common_samples]\n",
    "\n",
    "# remove genes that are constant across all samples\n",
    "df_bac = df_bac[list(df_bac.std()[df_bac.std()>0].index)]\n",
    "\n",
    "# select top 1000 genes based on averaged abundance\n",
    "df_bac_T = df_bac.T\n",
    "df_bac_T['sum'] = df_bac_T.sum(axis=1)\n",
    "df_bac_T = df_bac_T.sort_values('sum', ascending=False)\n",
    "df_bac_T = df_bac_T.head(1000).drop('sum', axis=1)\n",
    "df_bac = df_bac_T.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self-defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(X, Z, method=None): # X is test and Z is train\n",
    "    X.loc[:, \"is_z\"] = 0\n",
    "    Z.loc[:, \"is_z\"] = 1\n",
    "    XZ = pd.concat([X, Z],ignore_index=False) # keep index\n",
    "    labels = XZ['is_z'].values\n",
    "    XZ_mat = XZ.drop('is_z', axis=1).values\n",
    "     \n",
    "    # test if X and Z can be distinguished\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=3,random_state=0)\n",
    "    predictions = np.zeros(labels.shape)\n",
    "    skf = SKF(n_splits=20, shuffle=True, random_state=0)\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(XZ_mat, labels)):\n",
    "        X_train, X_test = XZ_mat[train_idx,:], XZ_mat[test_idx,:]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        probs = clf.predict_proba(X_test)[:, 1] # probability that each data point is a sample from training set\n",
    "        predictions[test_idx] = probs\n",
    "    roc_auc = AUC(labels, predictions)\n",
    "    \n",
    "    # weight_i = p_i(X|D)/p_i(Z|D)\n",
    "    predictions_Z = predictions[len(X):] # p(Z/D)\n",
    "    weights = (1./predictions_Z) - 1. # p(X|D)/p(Z/D)\n",
    "    weights /= np.mean(weights) # we do this to re-normalize the computed log-loss\n",
    "    XZ['size'] = 4\n",
    "    XZ.iloc[len(X):, XZ.columns.get_loc('size')] = 0.1 + weights*15\n",
    "    \n",
    "    # perform decomposition\n",
    "    if method is not None:\n",
    "        XZ = XZ.sort_index()\n",
    "        XZ_mat = XZ.drop(['is_z','size'], axis=1).values\n",
    "\n",
    "        # dimensionality reduction\n",
    "        if method=='UMAP':\n",
    "            fit = umap.UMAP(random_state=0)\n",
    "            u = fit.fit_transform(XZ_mat)\n",
    "            XZ_dec = pd.DataFrame(u, index=XZ.index, columns=['Axis1','Axis2'])\n",
    "        elif method=='PCoA':\n",
    "            dist_relab = distance.squareform(distance.pdist(XZ_mat, metric=\"braycurtis\"))\n",
    "            OrdinationResults = pcoa(dist_relab, number_of_dimensions=2)\n",
    "            XZ_dec = pd.DataFrame(OrdinationResults.samples.values, index=XZ.index, columns=['Axis1','Axis2'])\n",
    "        else:\n",
    "            print('uknown method: %s'%(method))\n",
    "            raise\n",
    "\n",
    "        XZ_dec['is_z'] = XZ['is_z']\n",
    "        XZ_dec['size'] = XZ['size']        \n",
    "        return roc_auc, weights, XZ_dec\n",
    "    else:\n",
    "        return roc_auc, weights, XZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = {}\n",
    "results = []\n",
    "use_weights=True\n",
    "plot_weights=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (A): 0.56\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 54.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group A, Acetate, best score and parameter combination = \n",
      "0.09784469663067623\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16, 'selectfrommodel__estimator__alpha': 0.001}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 46.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 48.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group A, Propionate, best score and parameter combination = \n",
      "0.35682575392507276\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 8, 'selectfrommodel__estimator__alpha': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 45.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 48.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group A, Butyrate, best score and parameter combination = \n",
      "0.40966361005417873\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.0001}\n",
      "\n",
      "\n",
      "ROC-AUC (B): 0.63\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  4.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d15c79b1feda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mCV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselectfrommodel__sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomforestregressor__sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    560\u001b[0m         \"\"\"\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# When workers are killed in such a brutal manner, they cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexecutor_manager_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0mexecutor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if use_weights and plot_weights:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,4), sharex=True, sharey=True)\n",
    "\n",
    "for k,group_to_exclude in enumerate(['A','B','C','D']):\n",
    "\n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.RandomizedGroup!=group_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.RandomizedGroup==group_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = df_bac.loc[samples_to_keep]\n",
    "    xdata_test = df_bac.loc[samples_to_exclude]\n",
    "    if use_weights:        \n",
    "        roc_auc[group_to_exclude], weights, df_ord = get_weights(X=deepcopy(xdata_test), Z=deepcopy(xdata_train), method='PCoA')\n",
    "        assert len(xdata_train)==len(weights)\n",
    "        print (\"ROC-AUC (%s): %2.2f\" % (group_to_exclude, roc_auc[group_to_exclude]))\n",
    "     \n",
    "        # show weights on train and test\n",
    "        if plot_weights:\n",
    "            # _ = sns.scatterplot(x='Axis1', y='Axis2', hue='is_z', size='size', data=df_ord, ax=ax[k])\n",
    "            df_ord_0 = df_ord.loc[df_ord.is_z==0]\n",
    "            _ = ax[k].scatter(df_ord_0['Axis1'], df_ord_0['Axis2'], marker='o', s=df_ord_0['size'], c='r', label='test')\n",
    "            df_ord_1 = df_ord.loc[df_ord.is_z==1]\n",
    "            _ = ax[k].scatter(df_ord_1['Axis1'], df_ord_1['Axis2'], marker='o', s=df_ord_1['size'], c='b', label='train')\n",
    "\n",
    "    xdata_train = np.asarray(xdata_train.values)\n",
    "    xdata_test = np.asarray(xdata_test.values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "\n",
    "        # make pipeline\n",
    "        # use standardscaler for transformation\n",
    "        # use lasso for feature selection\n",
    "        # use random forest for prediction\n",
    "        param_grid = {\n",
    "            'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "            'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "            'randomforestregressor__max_depth':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "        \n",
    "        clf1 = linear_model.Lasso(tol=1e-5,positive=True,random_state=0,max_iter=1000000)\n",
    "        clf2 = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), SelectFromModel(clf1, threshold=1e-5), clone(clf2))  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        if use_weights:\n",
    "            CV.fit(xdata_train, ydata_train, selectfrommodel__sample_weight=weights, randomforestregressor__sample_weight=weights)   \n",
    "        else:\n",
    "            CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Intrapolation, group %s, %s, best score and parameter combination = '%(group_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')\n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'test', sample_, day_, obs_, pred_])\n",
    "\n",
    "if use_weights and plot_weights:\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_weights and plot_weights:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,4), sharex=True, sharey=True)\n",
    "\n",
    "for k,vendor_to_exclude in enumerate(['Beijing','Guangdong','Hunan','Shanghai']):\n",
    "        \n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.Vendor!=vendor_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.Vendor==vendor_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = df_bac.loc[samples_to_keep]\n",
    "    xdata_test = df_bac.loc[samples_to_exclude]\n",
    "    if use_weights:\n",
    "        roc_auc[vendor_to_exclude], weights, df_ord = get_weights(X=xdata_test, Z=xdata_train, method='PCoA')\n",
    "        assert len(xdata_train)==len(weights)\n",
    "        print (\"ROC-AUC (%s): %2.2f\" % (vendor_to_exclude, roc_auc[vendor_to_exclude]))\n",
    "    \n",
    "        # show weights on train and test\n",
    "        if plot_weights:\n",
    "            # _ = sns.scatterplot(x='Axis1', y='Axis2', hue='is_z', size='size', data=df_ord, ax=ax[k])\n",
    "            df_ord_0 = df_ord.loc[df_ord.is_z==0]\n",
    "            _ = ax[k].scatter(df_ord_0['Axis1'], df_ord_0['Axis2'], marker='o', s=df_ord_0['size'], c='r', label='test')\n",
    "            df_ord_1 = df_ord.loc[df_ord.is_z==1]\n",
    "            _ = ax[k].scatter(df_ord_1['Axis1'], df_ord_1['Axis2'], marker='o', s=df_ord_1['size'], c='b', label='train')\n",
    "\n",
    "    xdata_train = np.asarray(xdata_train.values)\n",
    "    xdata_test = np.asarray(xdata_test.values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "\n",
    "        # make pipeline\n",
    "        # use lasso for feature selection\n",
    "        param_grid = {\n",
    "            'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "            'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "            'randomforestregressor__max_depth':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "        \n",
    "        clf1 = linear_model.Lasso(tol=1e-5,positive=True,random_state=0,max_iter=1000000)\n",
    "        clf2 = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), SelectFromModel(clf1, threshold=1e-5), clone(clf2))  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        if use_weights:\n",
    "            CV.fit(xdata_train, ydata_train, selectfrommodel__sample_weight=weights, randomforestregressor__sample_weight=weights)\n",
    "        else:\n",
    "            CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Extrapolation, vendor %s, %s, best score and parameter combination = '%(vendor_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')   \n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'test', sample_, day_, obs_, pred_])\n",
    "\n",
    "if use_weights and plot_weights:\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc_w_weights = pd.DataFrame.from_dict(roc_auc, orient='index').rename({0:'AUC'}, axis=1)\n",
    "df_roc_w_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(results, columns=['PerturbationType','SCFA','Permutation','PredictionType','SampleID','Day','ObservedValue','PredictedValue'])\n",
    "if use_weights:\n",
    "    df_prediction.to_csv('rf_prediction_predictor_asvonly_w_weights.csv')\n",
    "else:\n",
    "    df_prediction.to_csv('rf_prediction_predictor_asvonly_wo_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
