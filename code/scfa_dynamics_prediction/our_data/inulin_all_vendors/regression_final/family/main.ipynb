{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline                                           \n",
    "from sklearn.preprocessing import StandardScaler                                     \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.base import clone\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from skbio.stats.ordination import pcoa\n",
    "import umap\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta data\n",
    "df_meta = pd.read_csv('../../../../../../our_data/meta_data.csv', index_col=0)\n",
    "df_meta = df_meta[df_meta.Diet=='Inulin'] # only for inulin group\n",
    "df_meta = df_meta[df_meta.Day != 0] # remove day 0\n",
    "\n",
    "# read SCFA data\n",
    "df_scfa = pd.read_csv('../../../../../../our_data/SCFA.csv', index_col=0)\n",
    "\n",
    "# read bacterial abundance (family level)\n",
    "df_bac = pd.read_csv('../../../../../../our_data/16S_absolute_abundance_family.csv', index_col=0)\n",
    "\n",
    "# find common samples\n",
    "common_samples = list(set(df_meta.index).intersection(df_scfa.index).intersection(df_bac.index))\n",
    "df_meta = df_meta.loc[common_samples]\n",
    "df_scfa = df_scfa.loc[common_samples]\n",
    "df_bac = df_bac.loc[common_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self-defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(X, Z, method=None): # X is test and Z is train\n",
    "    X.loc[:, \"is_z\"] = 0\n",
    "    Z.loc[:, \"is_z\"] = 1\n",
    "    XZ = pd.concat([X, Z],ignore_index=True) # keep index\n",
    "    labels = XZ['is_z'].values\n",
    "    XZ_mat = XZ.drop('is_z', axis=1).values\n",
    "     \n",
    "    # test if X and Z can be distinguished\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=3,random_state=0)\n",
    "    predictions = np.zeros(labels.shape)\n",
    "    skf = SKF(n_splits=20, shuffle=True, random_state=0)\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(XZ_mat, labels)):\n",
    "        X_train, X_test = XZ_mat[train_idx,:], XZ_mat[test_idx,:]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        probs = clf.predict_proba(X_test)[:, 1] # probability that each data point is a sample from training set\n",
    "        predictions[test_idx] = probs\n",
    "    roc_auc = AUC(labels, predictions)\n",
    "    \n",
    "    # weight_i = p_i(X|D)/p_i(Z|D)\n",
    "    predictions_Z = predictions[len(X):] # p(Z/D)\n",
    "    weights = (1./predictions_Z) - 1. # p(X|D)/p(Z/D)\n",
    "    weights /= np.mean(weights) # we do this to re-normalize the computed log-loss\n",
    "    XZ['size'] = 4\n",
    "    XZ.iloc[len(X):, XZ.columns.get_loc('size')] = 0.1 + weights*15\n",
    "    \n",
    "    # perform decomposition\n",
    "    if method is not None:\n",
    "        XZ = XZ.sort_index()\n",
    "        XZ_mat = XZ.drop(['is_z','size'], axis=1).values\n",
    "\n",
    "        # dimensionality reduction\n",
    "        if method=='UMAP':\n",
    "            fit = umap.UMAP(random_state=0)\n",
    "            u = fit.fit_transform(XZ_mat)\n",
    "            XZ_dec = pd.DataFrame(u, index=XZ.index, columns=['Axis1','Axis2'])\n",
    "        elif method=='PCoA':\n",
    "            dist_relab = distance.squareform(distance.pdist(XZ_mat, metric=\"braycurtis\"))\n",
    "            OrdinationResults = pcoa(dist_relab, number_of_dimensions=2)\n",
    "            XZ_dec = pd.DataFrame(OrdinationResults.samples.values, index=XZ.index, columns=['Axis1','Axis2'])\n",
    "        else:\n",
    "            print('uknown method: %s'%(method))\n",
    "            raise\n",
    "\n",
    "        XZ_dec['is_z'] = XZ['is_z']\n",
    "        XZ_dec['size'] = XZ['size']        \n",
    "        return roc_auc, weights, XZ_dec\n",
    "    else:\n",
    "        return roc_auc, weights, XZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = {}\n",
    "results = []\n",
    "use_weights=False\n",
    "plot_weights=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 47.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group A, Acetate, best score and parameter combination = \n",
      "0.10216139254528415\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 47.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group A, Propionate, best score and parameter combination = \n",
      "0.38381973008110465\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group A, Butyrate, best score and parameter combination = \n",
      "0.41925416841134633\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 4, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group B, Acetate, best score and parameter combination = \n",
      "0.017802155025078648\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 16, 'selectfrommodel__estimator__alpha': 1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group B, Propionate, best score and parameter combination = \n",
      "0.42754789353460065\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.32, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 47.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group B, Butyrate, best score and parameter combination = \n",
      "0.44742304544871925\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 47.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group C, Acetate, best score and parameter combination = \n",
      "0.019145242871262534\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group C, Propionate, best score and parameter combination = \n",
      "0.4944354838856893\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group C, Butyrate, best score and parameter combination = \n",
      "0.35012523443810045\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.001}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group D, Acetate, best score and parameter combination = \n",
      "0.041222273360252235\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group D, Propionate, best score and parameter combination = \n",
      "0.45690150761701914\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 8, 'selectfrommodel__estimator__alpha': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrapolation, group D, Butyrate, best score and parameter combination = \n",
      "0.3248508369174573\n",
      "{'randomforestregressor__max_depth': 2, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.0001}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if use_weights and plot_weights:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,4), sharex=True, sharey=True)\n",
    "\n",
    "for k,group_to_exclude in enumerate(['A','B','C','D']):\n",
    "\n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.RandomizedGroup!=group_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.RandomizedGroup==group_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = df_bac.loc[samples_to_keep]\n",
    "    xdata_test = df_bac.loc[samples_to_exclude]\n",
    "    if use_weights:        \n",
    "        roc_auc[group_to_exclude], weights, df_ord = get_weights(X=xdata_test, Z=xdata_train, method='PCoA')\n",
    "        assert len(xdata_train)==len(weights)\n",
    "        print (\"ROC-AUC (%s): %2.2f\" % (group_to_exclude, roc_auc[group_to_exclude]))\n",
    "     \n",
    "        # show weights on train and test\n",
    "        if plot_weights:\n",
    "            # _ = sns.scatterplot(x='Axis1', y='Axis2', hue='is_z', size='size', data=df_ord, ax=ax[k])\n",
    "            df_ord_0 = df_ord.loc[df_ord.is_z==0]\n",
    "            _ = ax[k].scatter(df_ord_0['Axis1'], df_ord_0['Axis2'], marker='o', s=df_ord_0['size'], c='r', label='test')\n",
    "            df_ord_1 = df_ord.loc[df_ord.is_z==1]\n",
    "            _ = ax[k].scatter(df_ord_1['Axis1'], df_ord_1['Axis2'], marker='o', s=df_ord_1['size'], c='b', label='train')\n",
    "\n",
    "    xdata_train = np.asarray(xdata_train.values)\n",
    "    xdata_test = np.asarray(xdata_test.values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "\n",
    "        # make pipeline\n",
    "        # use standardscaler for transformation\n",
    "        # use lasso for feature selection\n",
    "        # use random forest for prediction\n",
    "        param_grid = {\n",
    "            'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "            'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "            'randomforestregressor__max_depth':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "        \n",
    "        clf1 = linear_model.Lasso(tol=1e-5,positive=True,random_state=0,max_iter=1000000)\n",
    "        clf2 = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), SelectFromModel(clf1, threshold=1e-5), clone(clf2))  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        if use_weights:\n",
    "            CV.fit(xdata_train, ydata_train, selectfrommodel__sample_weight=weights, randomforestregressor__sample_weight=weights)   \n",
    "        else:\n",
    "            CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Intrapolation, group %s, %s, best score and parameter combination = '%(group_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')\n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'test', sample_, day_, obs_, pred_])\n",
    "\n",
    "if use_weights and plot_weights:\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Beijing, Acetate, best score and parameter combination = \n",
      "0.19645703127339798\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.0001}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Beijing, Propionate, best score and parameter combination = \n",
      "0.5371959474771982\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 8, 'selectfrommodel__estimator__alpha': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 45.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Beijing, Butyrate, best score and parameter combination = \n",
      "0.3610997654755839\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.0001}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Guangdong, Acetate, best score and parameter combination = \n",
      "-0.017702489490492867\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.0001}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Guangdong, Propionate, best score and parameter combination = \n",
      "0.4549194025458405\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.0001}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 45.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Guangdong, Butyrate, best score and parameter combination = \n",
      "0.3968641107217252\n",
      "{'randomforestregressor__max_depth': 2, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Hunan, Acetate, best score and parameter combination = \n",
      "0.002081231344603851\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Hunan, Propionate, best score and parameter combination = \n",
      "0.43933551505228674\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Hunan, Butyrate, best score and parameter combination = \n",
      "0.5181045870000514\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 546.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 552.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 555.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Shanghai, Acetate, best score and parameter combination = \n",
      "0.051387654133858526\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 46.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Shanghai, Propionate, best score and parameter combination = \n",
      "0.1961007483722696\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 35.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 44.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Shanghai, Butyrate, best score and parameter combination = \n",
      "0.17680667885560034\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 4, 'selectfrommodel__estimator__alpha': 0.01}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if use_weights and plot_weights:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,4), sharex=True, sharey=True)\n",
    "\n",
    "for k,vendor_to_exclude in enumerate(['Beijing','Guangdong','Hunan','Shanghai']):\n",
    "        \n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.Vendor!=vendor_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.Vendor==vendor_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = df_bac.loc[samples_to_keep]\n",
    "    xdata_test = df_bac.loc[samples_to_exclude]\n",
    "    if use_weights:\n",
    "        roc_auc[vendor_to_exclude], weights, df_ord = get_weights(X=xdata_test, Z=xdata_train, method='PCoA')\n",
    "        assert len(xdata_train)==len(weights)\n",
    "        print (\"ROC-AUC (%s): %2.2f\" % (vendor_to_exclude, roc_auc[vendor_to_exclude]))\n",
    "    \n",
    "        # show weights on train and test\n",
    "        if plot_weights:\n",
    "            # _ = sns.scatterplot(x='Axis1', y='Axis2', hue='is_z', size='size', data=df_ord, ax=ax[k])\n",
    "            df_ord_0 = df_ord.loc[df_ord.is_z==0]\n",
    "            _ = ax[k].scatter(df_ord_0['Axis1'], df_ord_0['Axis2'], marker='o', s=df_ord_0['size'], c='r', label='test')\n",
    "            df_ord_1 = df_ord.loc[df_ord.is_z==1]\n",
    "            _ = ax[k].scatter(df_ord_1['Axis1'], df_ord_1['Axis2'], marker='o', s=df_ord_1['size'], c='b', label='train')\n",
    "\n",
    "    xdata_train = np.asarray(xdata_train.values)\n",
    "    xdata_test = np.asarray(xdata_test.values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "\n",
    "        # make pipeline\n",
    "        # use lasso for feature selection\n",
    "        param_grid = {\n",
    "            'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "            'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "            'randomforestregressor__max_depth':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "            'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "        \n",
    "        clf1 = linear_model.Lasso(tol=1e-5,positive=True,random_state=0,max_iter=1000000)\n",
    "        clf2 = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), SelectFromModel(clf1, threshold=1e-5), clone(clf2))  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        if use_weights:\n",
    "            CV.fit(xdata_train, ydata_train, selectfrommodel__sample_weight=weights, randomforestregressor__sample_weight=weights)\n",
    "        else:\n",
    "            CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Extrapolation, vendor %s, %s, best score and parameter combination = '%(vendor_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')   \n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'test', sample_, day_, obs_, pred_])\n",
    "\n",
    "if use_weights and plot_weights:\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.432822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.475415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.529167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.585030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <td>0.997114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangdong</th>\n",
       "      <td>0.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hunan</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanghai</th>\n",
       "      <td>0.999711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUC\n",
       "A          0.432822\n",
       "B          0.475415\n",
       "C          0.529167\n",
       "D          0.585030\n",
       "Beijing    0.997114\n",
       "Guangdong  0.989583\n",
       "Hunan      1.000000\n",
       "Shanghai   0.999711"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc_w_weights = pd.DataFrame.from_dict(roc_auc, orient='index').rename({0:'AUC'}, axis=1)\n",
    "df_roc_w_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(results, columns=['PerturbationType','SCFA','Permutation','PredictionType','SampleID','Day','ObservedValue','PredictedValue'])\n",
    "if use_weights:\n",
    "    df_prediction.to_csv('rf_prediction_predictor_familyonly_w_weights.csv')\n",
    "else:\n",
    "    df_prediction.to_csv('rf_prediction_predictor_familyonly_wo_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
