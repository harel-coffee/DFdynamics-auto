{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline                                           \n",
    "from sklearn.preprocessing import StandardScaler                                     \n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector, RFE\n",
    "from sklearn.base import clone\n",
    "%run -i '../../../../../../utils.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta data\n",
    "df_meta = pd.read_csv('../../../../../../our_data/meta_data.csv', index_col=0)\n",
    "df_meta = df_meta[df_meta.Diet=='Inulin'] # only for inulin group\n",
    "df_meta = df_meta[df_meta.Day != 0] # remove day 0\n",
    "\n",
    "# read SCFA data\n",
    "df_scfa = pd.read_csv('../../../../../../our_data/SCFA.csv', index_col=0)\n",
    "\n",
    "# read bacterial abundance\n",
    "df_bac = pd.read_csv('../../../../../../our_data/16S_absolute_abundance_species.csv', index_col=0)\n",
    "\n",
    "# find common samples\n",
    "common_samples = list(set(df_meta.index).intersection(df_scfa.index).intersection(df_bac.index))\n",
    "df_meta = df_meta.loc[common_samples]\n",
    "df_scfa = df_scfa.loc[common_samples]\n",
    "df_bac = df_bac.loc[common_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acetate Beijing\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Acetate Guangdong\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Acetate Hunan\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Acetate Shanghai\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Propionate Beijing\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Propionate Guangdong\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Propionate Hunan\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Propionate Shanghai\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Butyrate Beijing\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Butyrate Guangdong\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Butyrate Hunan\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Butyrate Shanghai\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "# parameters to run model training\n",
    "method = 'selectfrommodel' # selectfrommodel or sequentialfeatureselector, or rfe\n",
    "n_features_to_select = 10 # number of features to be kept\n",
    "\n",
    "# model training\n",
    "lines = []\n",
    "for scfa in ['Acetate','Propionate','Butyrate']:\n",
    "    for vendor_to_exclude in ['Beijing','Guangdong','Hunan','Shanghai']:\n",
    "        print(scfa, vendor_to_exclude)\n",
    "        \n",
    "        # split train/test data\n",
    "        mice_to_keep = list(set(df_meta[df_meta.Vendor!=vendor_to_exclude].MiceID))\n",
    "        samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "        mice_to_exclude = list(set(df_meta[df_meta.Vendor==vendor_to_exclude].MiceID))\n",
    "        samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "        \n",
    "        # get X and Y data\n",
    "        xdata_train = np.asarray(df_bac.loc[samples_to_keep].values)\n",
    "        xdata_test = np.asarray(df_bac.loc[samples_to_exclude].values)\n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "\n",
    "        n_features = xdata_train.shape[1]\n",
    "        max_features = ['auto','sqrt','log2', 0.1, 0.2, 0.5]\n",
    "        \n",
    "        # make pipeline\n",
    "        clf = RandomForestRegressor(n_estimators=2000, random_state=0)\n",
    "        if method=='selectfrommodel':\n",
    "            pipe = make_pipeline(StandardScaler(), SelectFromModel(clf, max_features=n_features_to_select, threshold=-np.inf), clone(clf))  \n",
    "        if method=='sequentialfeatureselector':\n",
    "            pipe = make_pipeline(StandardScaler(), SequentialFeatureSelector(clf, n_features_to_select=n_features_to_select, direction='forward', scoring='r2', cv=5, n_jobs=-1), clone(clf))  \n",
    "        if method=='rfe':\n",
    "            pipe = make_pipeline(StandardScaler(), RFE(clf, step=10, n_features_to_select=n_features_to_select, verbose=2), clone(clf))\n",
    "        random_grid = {'%s__estimator__max_features'%(method): max_features,\n",
    "                       'randomforestregressor__max_features': max_features\n",
    "                      }\n",
    "        rf_pipe = GridSearchCV(estimator=pipe, param_grid=random_grid, cv=5, verbose=2, n_jobs=-1, scoring='r2')\n",
    "        rf_pipe.fit(xdata_train, ydata_train)\n",
    "        \n",
    "        # predict training set\n",
    "        ydata_train_predicted = rf_pipe.predict(xdata_train)\n",
    "        ydata_test_predicted = rf_pipe.predict(xdata_test)\n",
    "\n",
    "        for mice_,obs_, pred_ in zip(mice_to_keep, ydata_train, ydata_train_predicted):\n",
    "            lines.append([scfa, vendor_to_exclude, 'train', mice_, obs_, pred_])\n",
    "        for mice_,obs_, pred_ in zip(mice_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            lines.append([scfa, vendor_to_exclude, 'test', mice_, obs_, pred_])\n",
    "\n",
    "df_pred = pd.DataFrame(lines, columns=['SCFA','Vendor2Exclude','Train/Test','MiceID','ObservedValue','PredictedValue'])\n",
    "df_pred.to_csv('rf_prediction_extrapolation_maxfeature%d_%s.csv'%(n_features_to_select, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
