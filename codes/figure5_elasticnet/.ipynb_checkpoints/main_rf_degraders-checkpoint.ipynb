{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline                                           \n",
    "from sklearn.preprocessing import StandardScaler                                     \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.base import clone\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from skbio.stats.ordination import pcoa\n",
    "import umap\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta data\n",
    "df_meta = pd.read_csv('../../our_data/meta_data.csv', index_col=0)\n",
    "df_meta = df_meta[df_meta.Diet=='Inulin']\n",
    "df_meta = df_meta[df_meta.Day != 0] # remove day 0\n",
    "\n",
    "# read SCFA data\n",
    "df_scfa = pd.read_csv('../../our_data/SCFA.csv', index_col=0)\n",
    "\n",
    "# read bacterial abundance (species level)\n",
    "df_bac = pd.read_csv('../../our_data/16S_absolute_abundance_species.csv', index_col=0)\n",
    "\n",
    "# find common samples\n",
    "common_samples = list(set(df_meta.index).intersection(df_scfa.index).intersection(df_bac.index))\n",
    "df_meta = df_meta.loc[common_samples]\n",
    "df_scfa = df_scfa.loc[common_samples]\n",
    "df_bac = df_bac.loc[common_samples]\n",
    "\n",
    "# remove species that are constant across all samples\n",
    "df_bac = df_bac[list(df_bac.std()[df_bac.std()>0].index)]\n",
    "df_bac = df_bac[['Bacteroides-acidifaciens','Muribaculaceae','Faecalibaculum','Parasutterella','Bacteroides']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.5s\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for k,group_to_exclude in enumerate(['A','B','C','D']):\n",
    "\n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.RandomizedGroup!=group_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.RandomizedGroup==group_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = np.asarray(df_bac.loc[samples_to_keep].values)\n",
    "    xdata_test = np.asarray(df_bac.loc[samples_to_exclude].values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "        param_grid = {\n",
    "        #'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "        'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "        'randomforestregressor__max_depth':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), clf)  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Intrapolation, group %s, %s, best score and parameter combination = '%(group_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')\n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'test', sample_, day_, obs_, pred_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Beijing, Acetate, best score and parameter combination = \n",
      "0.02713356494362864\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.3}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Beijing, Propionate, best score and parameter combination = \n",
      "0.18968478800635144\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Beijing, Butyrate, best score and parameter combination = \n",
      "-0.06591204973773598\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.9}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Guangdong, Acetate, best score and parameter combination = \n",
      "-0.05020651129833682\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.1}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Guangdong, Propionate, best score and parameter combination = \n",
      "0.21971550214620145\n",
      "{'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.99}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Guangdong, Butyrate, best score and parameter combination = \n",
      "0.04287714941258327\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Hunan, Acetate, best score and parameter combination = \n",
      "0.01982080044389074\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Hunan, Propionate, best score and parameter combination = \n",
      "0.28979984097584327\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Hunan, Butyrate, best score and parameter combination = \n",
      "-0.0306312724113152\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.01}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Shanghai, Acetate, best score and parameter combination = \n",
      "-0.23903764754964535\n",
      "{'elasticnet__alpha': 10, 'elasticnet__l1_ratio': 0.3}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation, vendor Shanghai, Propionate, best score and parameter combination = \n",
      "-0.048266239198727814\n",
      "{'elasticnet__alpha': 10, 'elasticnet__l1_ratio': 0.3}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "Extrapolation, vendor Shanghai, Butyrate, best score and parameter combination = \n",
      "-0.1026147354163609\n",
      "{'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.7}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "for k,vendor_to_exclude in enumerate(['Beijing','Guangdong','Hunan','Shanghai']):\n",
    "        \n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.Vendor!=vendor_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.Vendor==vendor_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = np.asarray(df_bac.loc[samples_to_keep].values)\n",
    "    xdata_test = np.asarray(df_bac.loc[samples_to_exclude].values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "        param_grid = {\n",
    "        #'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "        'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "        'randomforestregressor__max_depth':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), clf)  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Extrapolation, vendor %s, %s, best score and parameter combination = '%(vendor_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')   \n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'test', sample_, day_, obs_, pred_])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(results, columns=['PerturbationType','SCFA','Permutation','PredictionType','SampleID','Day','ObservedValue','PredictedValue'])\n",
    "df_prediction.to_csv('rf_prediction_predictor_speciesonly_rf_degraders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
