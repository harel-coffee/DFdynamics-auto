{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline                                           \n",
    "from sklearn.preprocessing import StandardScaler                                     \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.base import clone\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta data\n",
    "df_meta = pd.read_csv('../../our_data/meta_data.csv', index_col=0)\n",
    "df_meta = df_meta[df_meta.Diet=='Inulin']\n",
    "df_meta = df_meta[df_meta.Day != 0] # remove day 0\n",
    "\n",
    "# read SCFA data\n",
    "df_scfa = pd.read_csv('../../our_data/SCFA.csv', index_col=0)\n",
    "\n",
    "# read bacterial abundance (species level)\n",
    "df_bac = pd.read_csv('../../our_data/16S_absolute_abundance_species.csv', index_col=0)\n",
    "\n",
    "# find common samples\n",
    "common_samples = list(set(df_meta.index).intersection(df_scfa.index).intersection(df_bac.index))\n",
    "df_meta = df_meta.loc[common_samples]\n",
    "df_scfa = df_scfa.loc[common_samples]\n",
    "df_bac = df_bac.loc[common_samples]\n",
    "\n",
    "# remove species that are constant across all samples\n",
    "df_bac = df_bac[list(df_bac.std()[df_bac.std()>0].index)]\n",
    "df_bac = df_bac[['Bacteroides-acidifaciens','Muribaculaceae','Faecalibaculum','Parasutterella','Bacteroides']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group A, Acetate, best score and parameter combination = \n",
      "0.016344294047473375\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group A, Propionate, best score and parameter combination = \n",
      "0.3764453558420121\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group A, Butyrate, best score and parameter combination = \n",
      "0.30859971128582153\n",
      "{'randomforestregressor__max_depth': 2, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group B, Acetate, best score and parameter combination = \n",
      "0.02678463677582561\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group B, Propionate, best score and parameter combination = \n",
      "0.422127651006568\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group B, Butyrate, best score and parameter combination = \n",
      "0.2769221865555397\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group C, Acetate, best score and parameter combination = \n",
      "-0.052672938036000816\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group C, Propionate, best score and parameter combination = \n",
      "0.43167218209950453\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group C, Butyrate, best score and parameter combination = \n",
      "0.2194397016023828\n",
      "{'randomforestregressor__max_depth': 2, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group D, Acetate, best score and parameter combination = \n",
      "0.11169975258489288\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group D, Propionate, best score and parameter combination = \n",
      "0.4373730117966989\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 4}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Intrapolation, group D, Butyrate, best score and parameter combination = \n",
      "0.33711738460166846\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for k,group_to_exclude in enumerate(['A','B','C','D']):\n",
    "\n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.RandomizedGroup!=group_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.RandomizedGroup==group_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = np.asarray(df_bac.loc[samples_to_keep].values)\n",
    "    xdata_test = np.asarray(df_bac.loc[samples_to_exclude].values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "        param_grid = {\n",
    "        #'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "        'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "        'randomforestregressor__max_depth':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=2000,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), clf)  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Intrapolation, group %s, %s, best score and parameter combination = '%(group_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')\n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['intrapolation', scfa, group_to_exclude, 'test', sample_, day_, obs_, pred_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Beijing, Acetate, best score and parameter combination = \n",
      "0.14147901851327319\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Beijing, Propionate, best score and parameter combination = \n",
      "0.5030387559947538\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Beijing, Butyrate, best score and parameter combination = \n",
      "0.2666769314745001\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Guangdong, Acetate, best score and parameter combination = \n",
      "0.028197217841041032\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Guangdong, Propionate, best score and parameter combination = \n",
      "0.4606883894366146\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Guangdong, Butyrate, best score and parameter combination = \n",
      "0.4419403851592218\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Hunan, Acetate, best score and parameter combination = \n",
      "0.08246965299652001\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 8}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Hunan, Propionate, best score and parameter combination = \n",
      "0.43923228182723256\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Hunan, Butyrate, best score and parameter combination = \n",
      "0.32138032914517306\n",
      "{'randomforestregressor__max_depth': 8, 'randomforestregressor__max_features': 0.64, 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Shanghai, Acetate, best score and parameter combination = \n",
      "-0.044602832781013665\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 0.16, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 2}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Shanghai, Propionate, best score and parameter combination = \n",
      "0.11040847569843708\n",
      "{'randomforestregressor__max_depth': 16, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Extrapolation, vendor Shanghai, Butyrate, best score and parameter combination = \n",
      "-0.22390880632142754\n",
      "{'randomforestregressor__max_depth': 4, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 16}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,vendor_to_exclude in enumerate(['Beijing','Guangdong','Hunan','Shanghai']):\n",
    "        \n",
    "    # split train/test data\n",
    "    mice_to_keep = list(set(df_meta[df_meta.Vendor!=vendor_to_exclude].MiceID))\n",
    "    samples_to_keep = list(set(df_meta[df_meta.MiceID.isin(mice_to_keep)].index))\n",
    "    mice_to_exclude = list(set(df_meta[df_meta.Vendor==vendor_to_exclude].MiceID))\n",
    "    samples_to_exclude = list(set(df_meta[df_meta.MiceID.isin(mice_to_exclude)].index))\n",
    "\n",
    "    # get weights of training sets\n",
    "    xdata_train = np.asarray(df_bac.loc[samples_to_keep].values)\n",
    "    xdata_test = np.asarray(df_bac.loc[samples_to_exclude].values)\n",
    "    \n",
    "    # run random forest regression with weights\n",
    "    for scfa in ['Acetate','Propionate','Butyrate']:                \n",
    "        ydata_train = np.asarray(df_scfa.loc[samples_to_keep, scfa])\n",
    "        ydata_test = np.asarray(df_scfa.loc[samples_to_exclude, scfa])\n",
    "        param_grid = {\n",
    "        #'selectfrommodel__estimator__alpha':[10**v for v in [-4,-3,-2,-1,0]], # too large alpha will produce a null model (all features are 0)\n",
    "        'randomforestregressor__max_features':['auto','sqrt','log2',0.16,0.32,0.64],\n",
    "        'randomforestregressor__max_depth':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_split':[2,4,8,16],\n",
    "        'randomforestregressor__min_samples_leaf':[1,2,4]\n",
    "        }\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=200,random_state=0,oob_score=True)\n",
    "        pipe = make_pipeline(StandardScaler(), clf)  \n",
    "        CV = GridSearchCV(pipe, param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=2)\n",
    "        CV.fit(xdata_train, ydata_train)\n",
    "\n",
    "        print('Extrapolation, vendor %s, %s, best score and parameter combination = '%(vendor_to_exclude, scfa))\n",
    "        print(CV.best_score_)    \n",
    "        print(CV.best_params_)    \n",
    "        print('\\n')   \n",
    "\n",
    "        # predict training set\n",
    "        ydata_train_predicted = CV.predict(xdata_train)\n",
    "        ydata_test_predicted = CV.predict(xdata_test)\n",
    "\n",
    "        for sample_, obs_, pred_ in zip(samples_to_keep, ydata_train, ydata_train_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'train', sample_, day_, obs_, pred_])\n",
    "        for sample_, obs_, pred_ in zip(samples_to_exclude, ydata_test, ydata_test_predicted):\n",
    "            day_ = df_meta.loc[sample_,'Day']\n",
    "            results.append(['extrapolation', scfa, vendor_to_exclude, 'test', sample_, day_, obs_, pred_])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(results, columns=['PerturbationType','SCFA','Permutation','PredictionType','SampleID','Day','ObservedValue','PredictedValue'])\n",
    "df_prediction.to_csv('rf_prediction_predictor_speciesonly_rf_degraders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
